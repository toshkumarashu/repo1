{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ny8UoRrvnC7vyi0fehIlJ2QBe2NbiqFW",
      "authorship_tag": "ABX9TyOF21R3IWcDmWADaZuuWU0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toshkumarashu/repo1/blob/master/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning is a field in Machine Learning that deals with building and using Neural Network Models\n",
        "Neural Networks mimic the functuioning of a human brain.\n",
        "Neural Networks withs more than three layers are typically categorised as Deep Learning Networks\n",
        "\n",
        "Perceptron\n",
        "The perceptron is the unit for learning in an artificial neural network, A perceptron resembles a human brain cell.\n",
        "A perceptron is a single cell or node in an neural network"
      ],
      "metadata": {
        "id": "dLGPoROOPbA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Deep Learning we replace slope of model with weights called as w and intercept with the bias called as b.\n",
        "Weights and Biases become the parameters for a neural network.\n",
        "The number of weights equals the number of inputs/features."
      ],
      "metadata": {
        "id": "VXLh1jBOQY4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aritificial Neural Network\n",
        "An ANN is a network of perceptrons. A deep neural network usually has three or more layers.\n",
        "Each node has its own weights, biasesand acivation functin. Each node is connected to all the nodes in the next layer forming a dense network.\n",
        "Training an ANN means determining the right values for these parameters and hyperparameters such that it maximizes the accuracy of predictions for the given use case.\n"
      ],
      "metadata": {
        "id": "atz5oIx5Q0gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Architecture\n",
        "Input Layer\n",
        "The input to Deep Learning model is usually a vector of Numeric vaues.\n",
        "Vectors are usually defined using NumPy arrays. It represents the feature variables or independent variables that are used for prediction as well as training.\n",
        "Hidden Layer\n",
        "An ANN can have one or more hidden layers. The more the layers are the deep the network is .\n",
        "Each hidden layer can have one or more nodes. Typically the node count is configureed in range 2*n. Examples are 8,16,32,64,128 etc.\n",
        "A neural network is defined by the number of layers and nodes.\n",
        "The output of each node in previouslayer will become the inout for every node in the current layers.\n",
        "When there are more nodes and layers it ususlly results in better accuracy. As a general practice , start with small number and keep adding util an acceptable accuracy levels are obtained."
      ],
      "metadata": {
        "id": "L96NT8TTRcyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weights and Biases\n",
        "They form the basis for Deep Learning Algorithms . Weights and Biases are trainable parameters in a neural network model.\n",
        "Each input for each node will have an associated weight with it."
      ],
      "metadata": {
        "id": "MkctNnfSS3pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Fucntions\n",
        "An activation function plays an important role in creating the output of the node in the neural network.\n",
        "AN activation fucntin takes the martix output of the node and determines if and how the node will propagate information to the next layer.\n",
        "The main objective of activation function is that itconvers the output to a non-linear values. They serve as a critical step in helping a neural network learn specific patterns in the data.\n",
        "\n",
        "TanH- A TanH function normalizes the output in the range of (-1 ot +1)\n",
        "\n",
        "ReLu- Rectified Linear Unit- A ReLu produce a zero if the output is negative. Else, it will produce the same input verbatim.\n",
        "\n",
        "Softmax Function= This is used in the case of classification problems . It produces a vector of probabilites for each of thepossible classes in the outcomes. The class with the highes probability will be considered as the final class.\n",
        "These all activation functions are added as hyperparameters in the model."
      ],
      "metadata": {
        "id": "hExqelzvTNtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Layer\n",
        "The output layer is the final layer in the neural netork where desired predictions are obtained.\n",
        "\n",
        "Training a Neural Network Model\n",
        "Set up and intialisation- Converting data into numeric vectors. Splitting data into training, validation and test sets.\n",
        "\n",
        "Forward propagation-  Movement from input to hidden layer and then output layer.\n",
        "Measure Accurarcy and Error\n",
        "\n",
        "Backpropagation- If error is high, then it adusts weights and biases by the process of gradient descent to improve accurarcy.\n",
        "Gradient Descent is the process of repeating the forward and backward propagation in order to reduce error and move closer to the desired model.\n",
        "Batches and Epochs- 10000/10 (1000)\n",
        "\n",
        "Validation and Testing"
      ],
      "metadata": {
        "id": "q6M9SQZvUuII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Example- Iris Dataset**"
      ],
      "metadata": {
        "id": "qalwokv4qToh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Af5_fTgGPVS9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare input data for deep learining\n",
        "Load data into pandas dataframe\n",
        "convert the dataframe into anumy array\n",
        "Scale the feature dataset\n",
        "Use of onehot encoding for the largest variable\n",
        "Split the dataset into training and test datasets."
      ],
      "metadata": {
        "id": "C4KbLhB6q_K1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data and Review content"
      ],
      "metadata": {
        "id": "7f6hB2wmra5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data=pd.read_csv(\"iris.csv\")\n",
        "print(iris_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDsr-GyuqzI9",
        "outputId": "1aec7dd7-d704-448b-e8bd-e4e2fc876557"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "iris_data['variety']=label_encoder.fit_transform(iris_data['variety'])\n",
        "print(iris_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rafoRhMLrkBj",
        "outputId": "e34e3dd9-a95e-481f-8354-4438e1a3bf6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
            "0           5.1          3.5           1.4          0.2        0\n",
            "1           4.9          3.0           1.4          0.2        0\n",
            "2           4.7          3.2           1.3          0.2        0\n",
            "3           4.6          3.1           1.5          0.2        0\n",
            "4           5.0          3.6           1.4          0.2        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting into numpy array"
      ],
      "metadata": {
        "id": "32dtI8t0tlQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_iris=iris_data.to_numpy()\n",
        "print(np_iris.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNsJR8L9tN5d",
        "outputId": "481c4b91-e5e2-4d8e-851d-4df6c46c9c6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate features and target variables"
      ],
      "metadata": {
        "id": "v7HGxvZ7tkuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_data=np_iris[:,0:4]\n",
        "Y_data=np_iris[:,4]\n",
        "print(\"\\n Features before Scaling: \\n......................\")\n",
        "print(X_data[:5,:])\n",
        "print(\"\\n Target before one-hot encoding :\\n...................\")\n",
        "print(Y_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHRN1-mvt7ZN",
        "outputId": "0cd0da34-b738-4413-fa10-20db74dfd4e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Features before Scaling: \n",
            "......................\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "\n",
            " Target before one-hot encoding :\n",
            "...................\n",
            "[0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=StandardScaler().fit(X_data)\n",
        "\n",
        "# scale the nummeric freature variable\n",
        "X_data=scaler.transform(X_data)\n",
        "\n",
        "#Convert target varible as a one-hot encoded array\n",
        "Y_data=tf.keras.utils.to_categorical(Y_data,3)\n",
        "\n",
        "print(\"\\n Features afer Scaling :\\n-----------------\")\n",
        "\n",
        "print(X_data[:5,:])\n",
        "print(\"\\ntarget after one-hot encoding:\\n---------------------\")\n",
        "print(Y_data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O55ANR2pueRv",
        "outputId": "c6be604e-4694-4b3a-8cfb-c46240f56150"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Features afer Scaling :\n",
            "-----------------\n",
            "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
            " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
            " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
            " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
            " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
            "\n",
            "target after one-hot encoding:\n",
            "---------------------\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X_data,Y_data,test_size=0.10)\n",
        "print(\"\\n Train test Dimensions: \\n-------------------\")\n",
        "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMEWN6cPvL_x",
        "outputId": "1b8798b4-6329-4b26-bbd4-5371785266b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Train test Dimensions: \n",
            "-------------------\n",
            "(135, 4) (15, 4) (135, 3) (15, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Model\n",
        "\n",
        "Number of hidden layers\n",
        "\n",
        "Number of nodes in each layers\n",
        "\n",
        "Activation functions\n",
        "\n",
        "Loss function and accuracy measurements."
      ],
      "metadata": {
        "id": "6Zo06ZVDyOCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Number of classes in the target variable\n",
        "NB_CLASSES=3\n",
        "\n",
        "#create a swquential model in keras\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "#add the first hidden layer\n",
        "model.add(keras.layers.Dense(128, #Number of nodes\n",
        "                             input_shape=(4,), # number of input variable\n",
        "                             name=\"Hidden-Layer-1\", # Logical name\n",
        "                             activation=\"relu\")) # activation function\n",
        "\n",
        "# add a second hidden layer\n",
        "model.add(keras.layers.Dense(128,\n",
        "                            name=\"Hidden-Layer=2\",\n",
        "                            activation=\"relu\"))\n",
        "# add an output Layer with softmax function\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                             name=\"Output-Layer\",\n",
        "                             activation=\"softmax\"))\n",
        "# compile the model with Loss and mertrics\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "# print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "A5WKr7Z0w7Lw",
        "outputId": "2ae10189-ee19-41f1-e88e-681a51226066"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Hidden-Layer-1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden-Layer=2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output-Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Hidden-Layer-1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden-Layer=2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output-Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,539\u001b[0m (68.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,539</span> (68.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,539\u001b[0m (68.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,539</span> (68.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGnDtRZX0hXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}